{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f82ce35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'model0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2432a612",
   "metadata": {
    "id": "SHopJrGbBg_I"
   },
   "outputs": [],
   "source": [
    "import os, re, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59038ef3",
   "metadata": {
    "id": "m3gLXDJkBg_J"
   },
   "outputs": [],
   "source": [
    "#Text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#distance\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bab009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "loweralphabets=\"abcdefghijklmnopqrstuvwxyz\"\n",
    "upperalphabets=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "all_alphabets=loweralphabets+upperalphabets\n",
    "\n",
    "p = string.punctuation\n",
    "remv_punc = str.maketrans(\"\", \"\", p)\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f5a294",
   "metadata": {},
   "source": [
    "## Asking question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff693d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('pre_processed_all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b724ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_df_model0 : created with google-news-300 embeddings\n",
    "# w2v_df_model1 : created with combined review as corpus\n",
    "# w2v_df_model2 : created with individual reviews as corpus\n",
    "# w2v_df_model3 : created with reviews splitted to sentence level corpus\n",
    "# w2v_df_model4 : created with model 2 then replaced available vectors from google embeddings\n",
    "\n",
    "# Load back with memory-mapping = read-only, shared across processes.\n",
    "\n",
    "# w2v_df_model0 : created with google-news-300 embeddings\n",
    "# word2vec1.wordvectors : created with combined review as corpus\n",
    "# word2vec2.wordvectors : created with individual reviews as corpus\n",
    "# word2vec3.wordvectors : created with reviews splitted to sentence level corpus\n",
    "# word2vec4.wordvectors : created with model 2 then replaced available vectors from google embeddings\n",
    "\n",
    "if model == 'model0':\n",
    "    \n",
    "    w2v_df = pd.read_csv('w2v_df_model0.csv').drop('Unnamed: 0',axis=1)\n",
    "    embeddings = KeyedVectors.load_word2vec_format(r'C:\\Users\\asus\\Documents\\IPYNB Files\\CAPP\\GoogleNews-vectors-negative300\\GoogleNews-vectors-negative300.bin', binary = True)\n",
    "    \n",
    "elif model == 'model1':\n",
    "    \n",
    "    w2v_df = pd.read_csv('w2v_df_model1.csv').drop('Unnamed: 0',axis=1)\n",
    "    embeddings = KeyedVectors.load(\"word2vec1.wordvectors\", mmap='r')\n",
    "    \n",
    "elif model == 'model2':\n",
    "    \n",
    "    w2v_df = pd.read_csv('w2v_df_model2.csv').drop('Unnamed: 0',axis=1)\n",
    "    embeddings = KeyedVectors.load(\"word2vec2.wordvectors\", mmap='r')\n",
    "    \n",
    "elif model == 'model3':\n",
    "    \n",
    "    w2v_df = pd.read_csv('w2v_df_model3.csv').drop('Unnamed: 0',axis=1)\n",
    "    embeddings = KeyedVectors.load(\"word2vec3.wordvectors\", mmap='r')\n",
    "    \n",
    "elif model == 'model4':\n",
    "    \n",
    "    w2v_df = pd.read_csv('w2v_df_model4.csv').drop('Unnamed: 0',axis=1)\n",
    "    embeddings = KeyedVectors.load(\"word2vec4.wordvectors\", mmap='r')\n",
    "    \n",
    "elif model == 'model5':\n",
    "    \n",
    "    w2v_df = pd.read_csv('w2v_df_model5.csv').drop('Unnamed: 0',axis=1)\n",
    "    embeddings = KeyedVectors.load(\"word2vec5.wordvectors\", mmap='r')\n",
    "    \n",
    "elif model == 'model6':\n",
    "    \n",
    "    w2v_df = pd.read_csv('w2v_df_model6.csv').drop('Unnamed: 0',axis=1)\n",
    "    embeddings = KeyedVectors.load(\"word2vec6.wordvectors\", mmap='r')\n",
    "    \n",
    "elif model == 'model7':\n",
    "    \n",
    "    w2v_df = pd.read_csv('w2v_df_model7.csv').drop('Unnamed: 0',axis=1)\n",
    "    embeddings = KeyedVectors.load(\"word2vec7.wordvectors\", mmap='r')\n",
    "    \n",
    "elif model == 'model8':\n",
    "    \n",
    "    w2v_df = pd.read_csv('fasttext_df0.csv').drop('Unnamed: 0',axis=1)\n",
    "    embeddings = KeyedVectors.load(\"fasttext0.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab2702b",
   "metadata": {
    "id": "0gSs-pv5LKtp"
   },
   "outputs": [],
   "source": [
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "def process_one_sentence(sentence):\n",
    "    \n",
    "    #1. Converting the text into lower cases\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    #2.Removing stopwords\n",
    "    sentence = \" \".join([w for w in sentence.split() if w not in stop_words])\n",
    "\n",
    "    #3. Removing punctuation from all the tweets\n",
    "    sentence = sentence.translate(remv_punc)\n",
    "\n",
    "    #4. Remove white spaces\n",
    "    sentence = sentence.replace(\"  \", \" \").strip()\n",
    "\n",
    "    #5 . Remove emojis\n",
    "    sentence = remove_emojis(sentence)\n",
    "\n",
    "    if model not in ('model0','model4','model6','model7'):\n",
    "        sentence = \" \".join([ps.stem(w) for w in sentence.split()])\n",
    "\n",
    "    final = []\n",
    "    for word in sentence.split():\n",
    "        w = \"\"\n",
    "        for char in word:\n",
    "            if char in all_alphabets:\n",
    "                w = w + char\n",
    "        final.append(w)\n",
    "\n",
    "    sentence = \" \".join(final)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "# function to ask the question and return the places in the list sorted by cosine similarity.\n",
    "\n",
    "def ask_question_func(question):\n",
    "\n",
    "    # process the question first\n",
    "    question = process_one_sentence(question)\n",
    "    \n",
    "    doc_as_list = question.split()\n",
    "    \n",
    "    doc_len = len(doc_as_list)\n",
    "    \n",
    "    if model in ( 'model0', 'model4','model6','model7','model8') :\n",
    "        doc_vector = np.array([0]*300)\n",
    "    else:\n",
    "        doc_vector = np.array([0]*150)\n",
    "        \n",
    "    for word in doc_as_list: \n",
    "        try:\n",
    "            doc_vector = doc_vector + embeddings[word]  \n",
    "        except:\n",
    "            print('\\'',word ,'\\' word in question has no vector')\n",
    "            pass\n",
    "        \n",
    "    question_vector = doc_vector / doc_len\n",
    "    \n",
    "    # final df to be returned. This method of using a dictionary is much faster than adding to df everytime :) \n",
    "\n",
    "    distance_list = []\n",
    "    \n",
    "    for i in w2v_df.index:\n",
    "        distance_list.append({'place':data.loc[i, 'title'], 'State/UT':data.loc[i, 'State/UT'], 'cosine distance':cosine(w2v_df.loc[i,:], question_vector)})\n",
    "    \n",
    "    return_df = pd.DataFrame(sorted(distance_list, key=lambda d: d['cosine distance']))\n",
    "    \n",
    "    return return_df.reset_index().loc[:,['place','State/UT','cosine distance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b8f15",
   "metadata": {
    "id": "_QIXExgXLKtq"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question_func(\"elephant ride and jungle\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question_func(\"best beach in near airport where i can spend some time before flying\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bd463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ask_question_func(\"neat and clean beach where i can drive my car and watch sunset\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96568da8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "UVsp0LS9LKtr",
    "outputId": "32dc9350-a69f-43b4-8ffb-f1c85b8a1487",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# user question\n",
    "ask_question_func(\"i want to go to away to the hills with forests\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec57e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "NZd0fQS7LKtr",
    "outputId": "25481c9a-2175-473e-b199-7d629a8edc00",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# user question\n",
    "ask_question_func(\"i want to go to hill top park\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8087d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "RKCsO_FPLKtt",
    "outputId": "14d9ab97-8fc8-4a4e-e642-fd42baa649c3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# user question\n",
    "ask_question_func(\"lighthouse hills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34b057",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "9b1Qb77cLKtt",
    "outputId": "3ecfe649-3ea7-45e7-f5e8-edd5fdd5954d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# but the same question as beach\n",
    "ask_question_func(\"lighthouse on the hills and calm beach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50635dbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# but the same question as beach\n",
    "ask_question_func(\"best fort in jaipur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f34b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but the same question as beach\n",
    "\n",
    "ask_question_func(\"elephant ride and jungle\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70503b39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# but the same question as beach\n",
    "ask_question_func(\"wonderla park\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713eaaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ask_question_func(\"i want to go to a temple near kovalam beach\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6bbf74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ask_question_func(\"best beach in near airport where i can spend some time before flying\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bea81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question_func(\"varkala beach\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3237ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = 'I need to go to a place where I can spend time with family and kids in the evening with the breezy sea winds and \\\n",
    "night views of the sea. The place should be wonderful at night time with colorful lights. Also there should be some playing \\\n",
    "area for kids and seating for adults. I need the place to be located nearby a railway station or a bus terminus so that it could \\\n",
    "be easy to travel. '\n",
    "\n",
    "question2 = 'I want to do an adventure sport like Parasailing with my wife. So the activity should allow couple entry and also \\\n",
    "should have a guide for it. I am afraid of heights so I need a training session for parasailing before I try it out. The outdoor \\\n",
    "activity should be near a beach so that I can spend some quality time after the parasailing.'\n",
    "\n",
    "question3 = 'I need to take my kids to a children’s park where they can have some fun. The park should have swings and good \\\n",
    "walk paths with fountains. The park should be nearby some main attractions so that I can also visit some places with my \\\n",
    "family. If the park has some aquarium then it would be an added advantage. '\n",
    "\n",
    "question4 = 'I feel like going to a beach with crystal-clear waters. The place should have a great marine ecosystem with variety \\\n",
    "of fishes & coral reefs. The place should be an ideal location for water based activities like swimming, diving, snorkeling tec. \\\n",
    "It should also offer different adventure sports options like surfing & scuba diving.'\n",
    "\n",
    "print('\\nQuestion 1 result:\\n',question1,'\\n\\n',ask_question_func(question1).drop('cosine distance',axis=1).head())\n",
    "print('\\nQuestion 2 result:\\n',question2,'\\n\\n',ask_question_func(question2).drop('cosine distance',axis=1).head())\n",
    "print('\\nQuestion 3 result:\\n',question3,'\\n\\n',ask_question_func(question3).drop('cosine distance',axis=1).head())\n",
    "print('\\nQuestion 4 result:\\n',question4,'\\n\\n',ask_question_func(question4).drop('cosine distance',axis=1).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0dfb06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ask_question_func('I am planning to go on a beautiful holiday destination specially hills. There should be Sea '\n",
    "                  + 'side restaurants and sea view from hill where I can capture some good photos. After that '\n",
    "                  + 'I need to stay at a Resort nearby with parking facility. I love sea foods, so restaurants with '\n",
    "                  + 'sea foods should be around.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ce6214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ask_question_func('I want to experience a lovely cold breeze and beautiful green tea gardens, ' +\n",
    "                  'soothing views of distance hills. The place should be surrounded by mountains covered ' +\n",
    "                  'in dense fog so that I can feel like I am in midst of clouds. I also want to explore boating, ' + \n",
    "                  'echo point and gardens.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f201a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca3a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bc7fefb",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a2501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.rea"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
